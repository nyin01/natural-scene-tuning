{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "import statistics\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "from allensdk.core.brain_observatory_nwb_data_set import BrainObservatoryNwbDataSet\n",
    "from allensdk.brain_observatory.static_gratings import StaticGratings\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve saved data from two_photon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve directories\n",
    "save_dirs = []\n",
    "with open('../data/save_dirs.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        save_dirs.append(row[1])\n",
    "save_dirs = np.array(save_dirs)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each save_dir to obtain count id and exp id\n",
    "cont_ids = []\n",
    "exp_ids = []\n",
    "for i in range(len(save_dirs)):\n",
    "    cont_ids.append(save_dirs[i].split('cont_')[1].split('_exp')[0])\n",
    "    exp_ids.append(save_dirs[i].split('exp_')[1].split('_VISp')[0])\n",
    "cont_ids = np.array(cont_ids)\n",
    "exp_ids = np.array(exp_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['661437138', '603576130', '603425700', '670396939', '614418789',\n",
       "       '573720506', '511510675', '529763300', '511507811', '637998953',\n",
       "       '616886391', '686449283', '688678764'], dtype='<U9')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['662351346', '603889825', '603516552', '672674054', '614535829',\n",
       "       '574415929', '509962140', '529763302', '500860585', '638754323',\n",
       "       '636930038', '691208363', '690045763'], dtype='<U9')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>targeted_structure</th>\n",
       "      <th>cre_line</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>failed</th>\n",
       "      <th>layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661437138</td>\n",
       "      <td>175</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Slc17a7-IRES2-Cre</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>365251</td>\n",
       "      <td>Slc17a7-IRES2-Cre;Camk2a-tTA;Ai93-365251</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603576130</td>\n",
       "      <td>550</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Ntsr1-Cre_GN220</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>323982</td>\n",
       "      <td>Ntsr1-Cre_GN220;Ai148-323982</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603425700</td>\n",
       "      <td>550</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Ntsr1-Cre_GN220</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>323984</td>\n",
       "      <td>Ntsr1-Cre_GN220;Ai148-323984</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670396939</td>\n",
       "      <td>195</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Pvalb-IRES-Cre</td>\n",
       "      <td>Ai162(TIT2L-GC6s-ICL-tTA2)</td>\n",
       "      <td>369497</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai162-369497</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>614418789</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>332396</td>\n",
       "      <td>Sst-IRES-Cre;Ai148(CAM)-332396</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>573720506</td>\n",
       "      <td>275</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>297620</td>\n",
       "      <td>Sst-IRES-Cre;Ai148(CAM)-297620</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>511510675</td>\n",
       "      <td>275</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rorb-IRES2-Cre</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>228786</td>\n",
       "      <td>Rorb-IRES2-Cre;Camk2a-tTA;Ai93-228786</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>529763300</td>\n",
       "      <td>350</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>250605</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250605</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>511507811</td>\n",
       "      <td>350</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Scnn1a-Tg3-Cre</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>221470</td>\n",
       "      <td>Scnn1a-Tg3-Cre;Camk2a-tTA;Ai93-221470</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>637998953</td>\n",
       "      <td>400</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Fezf2-CreER</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>339839</td>\n",
       "      <td>Fezf2-CreER;Ai148-339839</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>616886391</td>\n",
       "      <td>400</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Fezf2-CreER</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>335660</td>\n",
       "      <td>Fezf2-CreER;Ai148(CAM)-335660</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>686449283</td>\n",
       "      <td>185</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Pvalb-IRES-Cre</td>\n",
       "      <td>Ai162(TIT2L-GC6s-ICL-tTA2)</td>\n",
       "      <td>379518</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai162-379518</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>688678764</td>\n",
       "      <td>205</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Slc17a7-IRES2-Cre</td>\n",
       "      <td>Ai94(TITL-GCaMP6s)</td>\n",
       "      <td>371307</td>\n",
       "      <td>Slc17a7-IRES2-Cre;Camk2a-tTA;Ai94-371307</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id imaging_depth targeted_structure           cre_line  \\\n",
       "0   661437138           175               VISp  Slc17a7-IRES2-Cre   \n",
       "1   603576130           550               VISp    Ntsr1-Cre_GN220   \n",
       "2   603425700           550               VISp    Ntsr1-Cre_GN220   \n",
       "3   670396939           195               VISp     Pvalb-IRES-Cre   \n",
       "4   614418789           375               VISp       Sst-IRES-Cre   \n",
       "5   573720506           275               VISp       Sst-IRES-Cre   \n",
       "6   511510675           275               VISp     Rorb-IRES2-Cre   \n",
       "7   529763300           350               VISp          Nr5a1-Cre   \n",
       "8   511507811           350               VISp     Scnn1a-Tg3-Cre   \n",
       "9   637998953           400               VISp        Fezf2-CreER   \n",
       "10  616886391           400               VISp        Fezf2-CreER   \n",
       "11  686449283           185               VISp     Pvalb-IRES-Cre   \n",
       "12  688678764           205               VISp  Slc17a7-IRES2-Cre   \n",
       "\n",
       "                 reporter_line donor_name  \\\n",
       "0           Ai93(TITL-GCaMP6f)     365251   \n",
       "1   Ai148(TIT2L-GC6f-ICL-tTA2)     323982   \n",
       "2   Ai148(TIT2L-GC6f-ICL-tTA2)     323984   \n",
       "3   Ai162(TIT2L-GC6s-ICL-tTA2)     369497   \n",
       "4   Ai148(TIT2L-GC6f-ICL-tTA2)     332396   \n",
       "5   Ai148(TIT2L-GC6f-ICL-tTA2)     297620   \n",
       "6           Ai93(TITL-GCaMP6f)     228786   \n",
       "7           Ai93(TITL-GCaMP6f)     250605   \n",
       "8           Ai93(TITL-GCaMP6f)     221470   \n",
       "9   Ai148(TIT2L-GC6f-ICL-tTA2)     339839   \n",
       "10  Ai148(TIT2L-GC6f-ICL-tTA2)     335660   \n",
       "11  Ai162(TIT2L-GC6s-ICL-tTA2)     379518   \n",
       "12          Ai94(TITL-GCaMP6s)     371307   \n",
       "\n",
       "                               specimen_name tags failed layer  \n",
       "0   Slc17a7-IRES2-Cre;Camk2a-tTA;Ai93-365251   []  False    23  \n",
       "1               Ntsr1-Cre_GN220;Ai148-323982   []  False     6  \n",
       "2               Ntsr1-Cre_GN220;Ai148-323984   []  False     6  \n",
       "3                Pvalb-IRES-Cre;Ai162-369497   []  False    23  \n",
       "4             Sst-IRES-Cre;Ai148(CAM)-332396   []  False     5  \n",
       "5             Sst-IRES-Cre;Ai148(CAM)-297620   []  False     4  \n",
       "6      Rorb-IRES2-Cre;Camk2a-tTA;Ai93-228786   []  False     4  \n",
       "7           Nr5a1-Cre;Camk2a-tTA;Ai93-250605   []  False     4  \n",
       "8      Scnn1a-Tg3-Cre;Camk2a-tTA;Ai93-221470   []  False     4  \n",
       "9                   Fezf2-CreER;Ai148-339839   []  False     5  \n",
       "10             Fezf2-CreER;Ai148(CAM)-335660   []  False     5  \n",
       "11               Pvalb-IRES-Cre;Ai162-379518   []  False    23  \n",
       "12  Slc17a7-IRES2-Cre;Camk2a-tTA;Ai94-371307   []  False    23  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve meta data for each container (contains layer info)\n",
    "subset_exp_cont_df = pd.read_csv('../data/subset_exp_cont_df.csv', dtype=str)\n",
    "# filter out the entries where the id is not in cont_ids\n",
    "subset_exp_cont_df = subset_exp_cont_df[subset_exp_cont_df['id'].isin(cont_ids)]\n",
    "subset_exp_cont_df = subset_exp_cont_df.reset_index(drop=True)\n",
    "subset_exp_cont_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve exp data\n",
    "all_experiment_data = []\n",
    "all_file_names = []\n",
    "for exp_id in exp_ids:\n",
    "    file_name = 'ophys_experiment_data/' + exp_id + '.nwb'\n",
    "    experiment_data = BrainObservatoryNwbDataSet(file_name)\n",
    "    all_file_names.append(file_name)\n",
    "    all_experiment_data.append(experiment_data)\n",
    "all_experiment_data = np.array(all_experiment_data)\n",
    "all_experiment_data.shape # 13 experiments left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each exp data, run the two_photon pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc = BrainObservatoryCache(manifest_file='../data/manifest.json')\n",
    "# helpers\n",
    "def get_ns(start, end, ns_img_list, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        ns_img_list.append(experiment_data.get_stimulus(i)[1])\n",
    "        next_i = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "        if (next_i == i):\n",
    "            break\n",
    "        i = next_i\n",
    "\n",
    "\n",
    "def get_stim(start, end,cell_dff, dff_stim_cell, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        j = experiment_data.get_stimulus(i)[0][2]['end']\n",
    "        max_dff_stim = max(cell_dff[i:j])\n",
    "        dff_stim_cell.append(max_dff_stim)\n",
    "        ts_in_next = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "        # start_next=experiment_data.get_stimulus(ts_in_next)[0][2]['start']\n",
    "        i = ts_in_next\n",
    "\n",
    "\n",
    "def get_stim_avg(start, end, cell_dff,dff_stim_cell, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        j = experiment_data.get_stimulus(i)[0][2]['end']\n",
    "        avg_dff_stim = sum(cell_dff[i:j])/len(cell_dff[i:j])\n",
    "        dff_stim_cell.append(avg_dff_stim)\n",
    "        i = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "\n",
    "\n",
    "def get_frames(start, end, ns_frame_list, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        ns_frame_list.append(experiment_data.get_stimulus(i)[0][2]['frame'])\n",
    "        i = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "\n",
    "\n",
    "def get_sg(start, end, ori_list, freq_list, phase_list, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        ori_list.append(experiment_data.get_stimulus(i)[0][2]['orientation'])\n",
    "        freq_list.append(experiment_data.get_stimulus(i)\n",
    "                         [0][2]['spatial_frequency'])\n",
    "        phase_list.append(experiment_data.get_stimulus(i)[0][2]['phase'])\n",
    "        i = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "\n",
    "\n",
    "def get_max(start, end, cell_dff, dff_sg_cell, experiment_data):\n",
    "    i = start\n",
    "    while i < end:\n",
    "        j = experiment_data.get_stimulus(i)[0][2]['end']\n",
    "        max_dff_stim = max(cell_dff[i:j])\n",
    "        dff_sg_cell.append(max_dff_stim)\n",
    "        i = experiment_data.get_stimulus(i)[0][2]['end']+1\n",
    "\n",
    "def peak_sig(list_peak_sig, avg_max_dff):\n",
    "    for j in range(len(avg_max_dff)):\n",
    "        max_dff = max(avg_max_dff[j])\n",
    "        list_mean_wo_max = []\n",
    "        for i in range(len(avg_max_dff[j])):\n",
    "            if avg_max_dff[j][i] != max_dff:\n",
    "                list_mean_wo_max.append(avg_max_dff[j][i])\n",
    "        mean_wo_max = statistics.mean(list_mean_wo_max)\n",
    "        peak_sig = max_dff/mean_wo_max\n",
    "        list_peak_sig.append(peak_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: container 603576130 experiement 603889825\n",
      "stimulus_epoch_df acquired.\n",
      "ns_start and ns_end acquired.\n",
      "ns_img_list acquired.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/_kzjxcq10d7727c9_qz6_ds80000gn/T/ipykernel_69458/3677269710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcell_dff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdff_stim_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mget_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_start1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_end1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell_dff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff_stim_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mget_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_start2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_end2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell_dff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff_stim_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mget_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_start3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_end3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_dff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdff_stim_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/62/_kzjxcq10d7727c9_qz6_ds80000gn/T/ipykernel_69458/1702593175.py\u001b[0m in \u001b[0;36mget_stim\u001b[0;34m(start, end, cell_dff, dff_stim_cell, experiment_data)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stimulus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmax_dff_stim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_dff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdff_stim_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_dff_stim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mts_in_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stimulus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "for i in range(len(save_dirs)):    \n",
    "    cont_id = cont_ids[i]\n",
    "    exp_id = exp_ids[i]\n",
    "    save_dir = save_dirs[i]\n",
    "    experiment_data = all_experiment_data[i]\n",
    "    file_name = all_file_names[i]\n",
    "\n",
    "    # handling the remaining experiments\n",
    "    # if save_dir contains 6 csv files, skip\n",
    "    if len(os.listdir(save_dir)) == 6:\n",
    "        continue\n",
    "\n",
    "\n",
    "    print('Running:', 'container', cont_id, 'experiement', exp_id)\n",
    "\n",
    "    # stimuli presented during each epoch: start and end frame #s for each stimulus epoch\n",
    "    stimulus_epoch_df = experiment_data.get_stimulus_epoch_table()\n",
    "    # print(stimulus_epoch_df)\n",
    "\n",
    "    print('stimulus_epoch_df acquired.')\n",
    "\n",
    "    # ts = timestamp (frame), dff=∆F/F at each frame\n",
    "    ts, dff = experiment_data.get_dff_traces()\n",
    "\n",
    "    # start and end frames for each stimulus epoch\n",
    "    ns_start1 = stimulus_epoch_df.loc[1]['start']\n",
    "    ns_end1 = stimulus_epoch_df.loc[1]['end']\n",
    "    ns_start2 = stimulus_epoch_df.loc[3]['start']\n",
    "    ns_end2 = stimulus_epoch_df.loc[3]['end']\n",
    "    ns_start3 = stimulus_epoch_df.loc[6]['start']\n",
    "    ns_end3 = stimulus_epoch_df.loc[6]['end']\n",
    "\n",
    "    print('ns_start and ns_end acquired.')\n",
    "\n",
    "\n",
    "    # making list of images as np arrays (not super needed but still nice)\n",
    "    ns_img_list = []\n",
    "    get_ns(ns_start1, ns_end1, ns_img_list, experiment_data)\n",
    "    get_ns(ns_start2, ns_end2, ns_img_list, experiment_data)\n",
    "    get_ns(ns_start3, ns_end3, ns_img_list, experiment_data)\n",
    "\n",
    "    print('ns_img_list acquired.')\n",
    "\n",
    "    # get diff traces for each frame\n",
    "    # remember ts = list of each frame, dff = ∆F/F at each frame\n",
    "    dff_stim_all = []  # dff_stim_all is a list of MAX dff over the interval of ONE natural scene presentation for EACH CELL\n",
    "    for k in range(len(dff)):\n",
    "        cell_dff=dff[k]\n",
    "        dff_stim_cell=[]\n",
    "        get_stim(ns_start1, ns_end1,cell_dff, dff_stim_cell, experiment_data)\n",
    "        get_stim(ns_start2, ns_end2,cell_dff, dff_stim_cell, experiment_data)\n",
    "        get_stim(ns_start3, ns_end3, cell_dff,dff_stim_cell, experiment_data)\n",
    "        dff_stim_all.append(dff_stim_cell)\n",
    "    \n",
    "    # same idea, but doing mean dff over an interval\n",
    "    dff_stim_avg=[] \n",
    "    for k in range(len(dff)):\n",
    "        cell_dff=dff[k]\n",
    "        dff_stim_cell=[]\n",
    "        get_stim_avg(ns_start1, ns_end1,\n",
    "                     cell_dff,dff_stim_cell, experiment_data)\n",
    "        get_stim_avg(ns_start2, ns_end2, cell_dff,dff_stim_cell, experiment_data)\n",
    "        get_stim_avg(ns_start3, ns_end3,\n",
    "                     cell_dff,dff_stim_cell, experiment_data)\n",
    "        dff_stim_avg.append(dff_stim_cell)\n",
    "\n",
    "    print('dff_stim_all and dff_stim_avg acquired.')\n",
    "\n",
    "    # Get the cell specimens information for this experiment\n",
    "    cell_specimens = boc.get_cell_specimens(experiment_container_ids=[cont_id])\n",
    "    cell_specimens_df = pd.DataFrame(cell_specimens)\n",
    "\n",
    "    # # Get experiment for our container id and stimuli of interest\n",
    "    # stim_2 = ['static_gratings']\n",
    "    # sg_experiment = boc.get_ophys_experiments(experiment_container_ids=[cont_id], stimuli=stim_2)\n",
    "\n",
    "    # # Download the experiment data using the experiment id\n",
    "    # if sg_experiment == []:\n",
    "    #     print('No static grating experiment for this container.')\n",
    "    #     continue\n",
    "    # experiment_id_2 = sg_experiment[0]['id']\n",
    "    # data_sg = boc.get_ophys_experiment_data(experiment_id_2)\n",
    "    # print('Data acquired.')\n",
    "    data_sg = experiment_data\n",
    "\n",
    "    print('sg Data acquired.')\n",
    "\n",
    "    # Create my StaticGratings Object\n",
    "    sg = StaticGratings(data_sg)\n",
    "    # Return dataframe of peak conditions\n",
    "    sg_df = sg.peak\n",
    "    cell_specimen_id = sg_df['cell_specimen_id']\n",
    "    num_cells = len(cell_specimen_id)\n",
    "    # multiplying by 30 and adding to list of preferred orientations\n",
    "    pref_ori = []\n",
    "    for i in range(num_cells):\n",
    "        pref_ori.append(sg_df['ori_sg'][i]*30)\n",
    "    pref_ori_dict = {\n",
    "        'cell_specimen_id': cell_specimen_id,\n",
    "        'pref_ori': pref_ori\n",
    "    }\n",
    "    pref_ori_df = pd.DataFrame(pref_ori_dict)\n",
    "\n",
    "    print('pref_ori_df acquired.')\n",
    "\n",
    "    # make sure cells with preferred orientations also in natural scenes experiment and vice versa\n",
    "    cell_ids = experiment_data.get_cell_specimen_ids()\n",
    "    cell_spec_id_ori = []\n",
    "    pref_ori_cell = []\n",
    "    for i in range(len(pref_ori_df['cell_specimen_id'])):\n",
    "        if pref_ori_df['cell_specimen_id'][i] in cell_ids:\n",
    "            cell_spec_id_ori.append(pref_ori_df['cell_specimen_id'][i])\n",
    "            pref_ori_cell.append(pref_ori_df['pref_ori'][i])\n",
    "\n",
    "    # Extract osi_sg (orientation selectivity index) and sf_index_sg (????frequency selectivity index)\n",
    "    osi_sg = sg_df['osi_sg']\n",
    "    # there isn't any documentation stating that this is the selectivity index, but just running with it\n",
    "    fsi_sg = sg_df['sf_index_sg']\n",
    "    si_dict = {\n",
    "        'cell_specimen_id': cell_specimen_id,\n",
    "        'osi_sg': osi_sg,\n",
    "        'fsi_sg': fsi_sg\n",
    "    }\n",
    "    si_df = pd.DataFrame(si_dict)\n",
    "    # visualize\n",
    "    plt.scatter(osi_sg, fsi_sg, s=5)\n",
    "    plt.xlabel('orientation selectivity index')\n",
    "    plt.ylabel('frequency selectivity index')\n",
    "    counts, bins = np.histogram(osi_sg)\n",
    "    plt.stairs(counts, bins)\n",
    "\n",
    "    # SUBSET CELLS IN CALCIUM DATA FOR NS TO COVER CELLS SHOWN SG\n",
    "    cell_id_subset = []\n",
    "    dff_subset = []\n",
    "    for i in range(len(cell_ids)):  \n",
    "        if cell_ids[i] in cell_spec_id_ori:\n",
    "            cell_id_subset.append(cell_ids[i])\n",
    "            dff_subset.append(dff_stim_all[i])\n",
    "    dff_subset_tuple = list(zip(cell_id_subset, dff_subset))\n",
    "    dff_subset_dict = dict(dff_subset_tuple)\n",
    "    dff_subset_df = pd.DataFrame(dff_subset_dict)\n",
    "    dff_subset_df_tp = dff_subset_df.transpose()\n",
    "    dff_subset_df_index = dff_subset_df_tp.reset_index()\n",
    "    dff_final_subset_df = dff_subset_df_index.rename(columns={'index':'cell_specimen_id'})\n",
    "    dff_final_subset_df.sort_values(by='cell_specimen_id')\n",
    "\n",
    "    # same provess with mean dff\n",
    "    cell_id_subset = []\n",
    "    dff_mean_subset = []\n",
    "    for i in range(len(cell_ids)): \n",
    "        if cell_ids[i] in cell_spec_id_ori:\n",
    "            cell_id_subset.append(cell_ids[i])\n",
    "            dff_mean_subset.append(dff_stim_avg[i])\n",
    "    mean_dff_subset_tuple = list(zip(cell_id_subset, dff_mean_subset))\n",
    "    mean_dff_subset_dict = dict(mean_dff_subset_tuple)\n",
    "    mean_dff_subset_df = pd.DataFrame(mean_dff_subset_dict)\n",
    "    mean_dff_final_subset_df = mean_dff_subset_df.transpose().reset_index().rename(columns={'index':'cell_specimen_id'})\n",
    "\n",
    "    # List of frame numbers for each natural scene presentation (better than a list of actual images themselves)\n",
    "    ns_frame_list = []\n",
    "    get_frames(ns_start1, ns_end1, ns_frame_list, experiment_data)\n",
    "    get_frames(ns_start2, ns_end2, ns_frame_list, experiment_data)\n",
    "    get_frames(ns_start3, ns_end3, ns_frame_list, experiment_data)\n",
    "    ns_frame_dict = {\n",
    "        'frame': ns_frame_list\n",
    "    }\n",
    "    ns_frame_df = pd.DataFrame(ns_frame_dict)\n",
    "\n",
    "    subset_pref_ori_dict={\n",
    "    'cell_specimen_id': cell_spec_id_ori,\n",
    "    'pref_ori': pref_ori_cell\n",
    "    }\n",
    "    subset_pref_ori_df=pd.DataFrame(subset_pref_ori_dict)\n",
    "    subset_pref_ori_df\n",
    "\n",
    "    # export as csvs, finally\n",
    "    # preferred orientation for each cell (in order by cell specimen id)\n",
    "    ordered_pref_ori_subset = subset_pref_ori_df.sort_values(\n",
    "        by='cell_specimen_id').reset_index().drop(['index'], axis=1)\n",
    "    ordered_pref_ori_subset.to_csv(\n",
    "        save_dir + 'pref_ori_ordered_subset.csv', sep=',', index=False)\n",
    "    # max dff for each NS presentation (in order by cell specimen id)\n",
    "    ordered_dff_final_subset = dff_final_subset_df.sort_values(\n",
    "        by='cell_specimen_id').reset_index().drop(['index'], axis=1)\n",
    "    ordered_dff_final_subset.to_csv(\n",
    "        save_dir + 'max_dff_subset_ordered.csv', sep=',', index=False)\n",
    "    # mean dff for each NS presentation (in order by cell specimen id)\n",
    "    ordered_mean_dff_subset = mean_dff_final_subset_df.sort_values(\n",
    "        by='cell_specimen_id').reset_index().drop(['index'], axis=1)\n",
    "    ordered_mean_dff_subset.to_csv(\n",
    "        save_dir + 'mean_dff_subset_ordered.csv', sep=',', index=False)\n",
    "    # frame of each natural scene presented throughout the experiment\n",
    "    ns_stimulus_frame_presentation = ns_frame_df.to_csv(save_dir + 'ns_stim_frame_presentation.csv', sep=',', index=False)\n",
    "\n",
    "    # OBTAIN LIST OF STATIC GRATING STIMULI IN ORDER OF PRESENTATION, GET DFF TRACES FOR EACH FRAME\n",
    "    # start and end frames for each stimulus epoch\n",
    "    sg_start1 = stimulus_epoch_df.loc[0]['start']\n",
    "    sg_end1 = stimulus_epoch_df.loc[0]['end']\n",
    "    sg_start2 = stimulus_epoch_df.loc[4]['start']\n",
    "    sg_end2 = stimulus_epoch_df.loc[4]['end']\n",
    "    sg_start3 = stimulus_epoch_df.loc[7]['start']\n",
    "    sg_end3 = stimulus_epoch_df.loc[7]['end']\n",
    "\n",
    "    # making dict (note, there are some random NaN in there... will deal with them)\n",
    "    ori_list = []\n",
    "    freq_list = []\n",
    "    phase_list = []\n",
    "    get_sg(sg_start1, sg_end1, ori_list, freq_list, phase_list, experiment_data)\n",
    "    get_sg(sg_start2, sg_end2, ori_list, freq_list, phase_list, experiment_data)\n",
    "    get_sg(sg_start3, sg_end3, ori_list, freq_list, phase_list, experiment_data)\n",
    "    sg_exp_dict = {\n",
    "        'orientation': ori_list,\n",
    "        'frequency': freq_list,\n",
    "        'phase': phase_list\n",
    "    }\n",
    "\n",
    "    # remember ts = list of each frame, dff = ∆F/F at each frame\n",
    "    dff_max_sg = []  # a list of MAX dff over the interval of ONE static grating presentation for EACH CELL\n",
    "    for k in range(len(dff)):\n",
    "        cell_dff = dff[k]\n",
    "        dff_sg_cell = []\n",
    "        get_max(sg_start1, sg_end1, cell_dff,dff_sg_cell, experiment_data)\n",
    "        get_max(sg_start2, sg_end2, cell_dff,dff_sg_cell, experiment_data)\n",
    "        get_max(sg_start3, sg_end3, cell_dff,dff_sg_cell, experiment_data)\n",
    "        dff_max_sg.append(dff_sg_cell)\n",
    "\n",
    "    # making a data frame\n",
    "    dff_sg_tuple=list(zip(cell_ids, dff_max_sg))\n",
    "    dff_sg_dict=dict(dff_sg_tuple)\n",
    "    dff_sg_df=pd.DataFrame(dff_sg_dict)\n",
    "    dff_sg_df_tp=dff_sg_df.transpose()\n",
    "    dff_sg_df_index=dff_sg_df_tp.reset_index()\n",
    "    dff_final_sg_df=dff_sg_df_index.rename(columns={'index':'cell_specimen_id'})\n",
    "    dff_final_sg_df=dff_final_sg_df.sort_values(by='cell_specimen_id').reset_index().drop(columns='index')\n",
    "    # transpose df to prepare to associate with orientation and frequency data\n",
    "    dff_final_sg_df_t=dff_final_sg_df.T\n",
    "    \n",
    "    # produce a list of lists for the average MAX dff of each cell for each ORIENTATION (averaging across each replicate)\n",
    "    degrees=[0, 30, 60, 90, 120, 150]\n",
    "    avg_max_dff_ori_all=[] # a list of lists: 122 lists (one for each cell), avg max dff for each ori (len 6)\n",
    "    for j in range(len(dff_final_sg_df)): # for each cell\n",
    "        img_max_dff_i=[[]for _ in range(len(degrees))] # empty list of 6 lists for each orientation\n",
    "        for i in range(0, len(dff_final_sg_df_t)-1): # adding max dff scores, sorted into each list by frame number\n",
    "            ori=ori_list[i]\n",
    "            if math.isnan(ori):\n",
    "                continue\n",
    "            max_dff=dff_final_sg_df_t[j][i]\n",
    "            img_max_dff_i[degrees.index(ori)].append(max_dff)\n",
    "        avg_max_dff_i=[]\n",
    "        for k in range(len(img_max_dff_i)):\n",
    "            avg_max_dff=statistics.mean(img_max_dff_i[k])\n",
    "            avg_max_dff_i.append(avg_max_dff)\n",
    "        avg_max_dff_ori_all.append(avg_max_dff_i)\n",
    "\n",
    "    freq_unique=[]\n",
    "    for i in range(len(freq_list)):\n",
    "        if freq_list[i] not in freq_unique:\n",
    "            freq_unique.append(freq_list[i])\n",
    "    freq_unique_value=[]\n",
    "    for i in range(len(freq_unique)):\n",
    "        if not math.isnan(freq_unique[i]):\n",
    "            freq_unique_value.append(freq_unique[i])\n",
    "    sorted_freq=sorted(freq_unique_value)\n",
    "\n",
    "    # produce a list of lists for the average MAX dff of each cell for each FREQUENCY (averaging across each replicate)\n",
    "    avg_max_dff_freq_all=[] # a list of lists: 122 lists (one for each cell), avg max dff for each freq (len 5)\n",
    "    for j in range(len(dff_final_sg_df)): # for each cell\n",
    "        img_max_dff_i=[[]for _ in range(len(sorted_freq))] # empty list of 6 lists for each orientation\n",
    "        for i in range(0, len(dff_final_sg_df_t)-1): # adding max dff scores, sorted into each list by frame number\n",
    "            freq=freq_list[i]\n",
    "            if math.isnan(freq):\n",
    "                continue\n",
    "            max_dff=dff_final_sg_df_t[j][i]\n",
    "            img_max_dff_i[sorted_freq.index(freq)].append(max_dff)\n",
    "        avg_max_dff_i=[]\n",
    "        for k in range(len(img_max_dff_i)):\n",
    "            avg_max_dff=statistics.mean(img_max_dff_i[k])\n",
    "            avg_max_dff_i.append(avg_max_dff)\n",
    "        avg_max_dff_freq_all.append(avg_max_dff_i)\n",
    "\n",
    "    ori_peak_sig=[]\n",
    "    freq_peak_sig=[]\n",
    "    peak_sig(ori_peak_sig, avg_max_dff_ori_all)\n",
    "    peak_sig(freq_peak_sig, avg_max_dff_freq_all)\n",
    "\n",
    "    # make a dict with cell ids\n",
    "    peak_sig_dict={\n",
    "        'cell_specimen_id': sorted(cell_ids),\n",
    "        'ori_peak_sig': ori_peak_sig,\n",
    "        'freq_peak_sig': freq_peak_sig\n",
    "    }\n",
    "    peak_sig_df=pd.DataFrame(peak_sig_dict)\n",
    "    plt.scatter(ori_peak_sig, freq_peak_sig, marker=\"o\", s=5)\n",
    "    plt.xlabel('orientation dff max/mean (exclusive of max)')\n",
    "    plt.ylabel('frequency dff max/mean (exclusive of max)')\n",
    "    sorted_sdk_osi_df=si_df.sort_values(by='cell_specimen_id')\n",
    "    sorted_sdk_osi_df.sort_values(by='osi_sg')\n",
    "    plt.scatter(ori_peak_sig, sorted_sdk_osi_df['osi_sg'].tolist(), s=5)\n",
    "    plt.xlabel('manual osi')\n",
    "    plt.ylabel('sdk osi')\n",
    "\n",
    "    counts, bins = np.histogram(ori_peak_sig, bins=20)\n",
    "    a = np.log(np.array(ori_peak_sig)-1)\n",
    "    two_std_log=len(a[(a-np.mean(a)) > 2*np.std(a)])\n",
    "    one_std_log=len(a[(a-np.mean(a)) > 1*np.std(a)])\n",
    "    b = np.array(ori_peak_sig)\n",
    "    two_std_linear=len(b[(b-np.mean(b)) > 2*np.std(b)])\n",
    "    one_std_linear=len(b[(b-np.mean(b)) > np.std(b)])\n",
    "    two_std_linear_df=peak_sig_df.sort_values(by='ori_peak_sig', ascending=False).head(two_std_linear)\n",
    "    one_std_linear_df=peak_sig_df.sort_values(by='ori_peak_sig', ascending=False).head(one_std_linear)\n",
    "    two_std_linear_df.to_csv(save_dir + 'two_std_linear.csv', index=False)\n",
    "    one_std_linear_df.to_csv(save_dir + 'one_std_linear.csv', index=False)\n",
    "    plt.hist(\n",
    "        np.log(np.array(ori_peak_sig)-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allensdk",
   "language": "python",
   "name": "allensdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
